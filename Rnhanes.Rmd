---
title: "nhanesA: Achieving Transparency and Reproducibility in NHANES Research"
author: ''
bibliography: references.bib  
# biblio-style: "apalike"
link-citations: true
output:
  pdf_document:
    citation_package: natbib
    # pandoc_args: [
    #   "-V", "classoption=twocolumn"
    # ]
  bookdown::pdf_book:
    citation_package: biblatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Abstract

The National Health and Nutrition Examination Survey (NHANES) covers a very broad array of topics including demography, sociology, health, and nutrition. It has been carried out in two year cycles starting in 1999 and the bulk of the data are public and available to any researcher. This has made them invaluable in very many areas of research. In this paper we describe methods to aid researchers in developing reproducible research in ways that will allow for sharing and extending previous efforts. We believe that community efforts to enhance reproducibility and sharing of analytic methods will greatly benefit the scientific community and will explain how adopting a few common strategies would be of widespread benefit. Specifically, we recommend researchers or authors to create reproducible works through Rmarkdown, `nhanesA`, and Github.

## Introduction

NHANES is a pivotal program of studies aimed at evaluating the health and nutritional well-being of both adults and children residing in the United States. Its distinctive feature lies in its comprehensive approach, which combines detailed interviews and thorough physical examinations. NHANES is administered by the National Center for Health Statistics (NCHS), an integral part of the Centers for Disease Control and Prevention (CDC), which holds the responsibility for generating crucial health and vital statistics for the entire nation.
 
Since 1999, the NHANES survey has been conducted continuously, and the surveys during that period are referred to as "continuous NHANES" to distinguish from several prior surveys. Continuous NHANES surveys are grouped in two-year *cycles*, with the first cycle carried out in 1999-2000.  For the most part the data are public and are very widely used for a variety of different analysis.  In fact, searching PubMed for the published papers that cite NHANES shows that currently more than 5,000 papers per year make some use of this resource. The bulk of the NHANES data are available for download from the CDC website, https://www.cdc.gov/nchs/nhanes.htm. Detailed instructions on using the data, how to download it and interpret it are given.
 
However, we have found that replication of published papers remains a challenging endeavor. In our experience even when authors have the best of intentions it is very difficult to replicate the tables and graphs in their papers. This is due to a variety of challenges that largely relate to a lack of specificity in reporting the extent and manner of data cleaning, the details of entry criteria or of case and control definitions, and whether, and if, any transformation or filtering of data points was carried out. While these processes are sometimes challenging to describe in prose they can be succinctly and accurately described in software.



[We may need a box that describes Markdown documents, Source/Version control systems]
\begin{figure}
  \includegraphics{images/process.jpg}
  \caption{Workflow for ensuring transparent and reproducible research: (1) Authors utilize RMarkdown and R files, managed with Git version control for organization and collaboration. The `nhanesA` package facilitates NHANES access. Git and GitHub facilitate this by archiving and source code control. (2) Work is committed, pushed, and made public on GitHub in the form of Rmarkdown and R files. (3) Any one who wants to reproduce the work can fork or clone the repository to reproduce or expand upon the work. They will access the NHANES database in the same way as the original authors. Contributions or extensions can be integrated via pull requests and subsequent merging.}
  \label{fig:process}
\end{figure}

The reproducibility of a paper, or result, can be enhanced by using a number of tools and processes that are commonly used for software development.  An important development was the concept of *markdown* [Laha: FIXME: probably better to follow https://en.wikipedia.org/wiki/Markdown for the history of markdown - you have Rmarkdown.
Also please put a link to the Rmarkdown cheatsheet in the appendix.]
\cite{Xie2018,Allaire2023}  documents which are documents that integrate software (code) and text. These can be thought of as explicit descriptions of how the figures and the tables in the published paper were created. Rmarkdown documents are processed by different *engines* that transform them into specific outputs such as a PDF format for publication or a HTML output for putting on the web. 

A second important tool to help with reproducibility is the use of version control systems. These were originally developed for software development but they work equally well for writing papers.  A very widely used tool for version control is GitHub (https://github.com/).  One example of using this approach based on R (@Ihaka1996) is the Epidemiologist R Handbook (https://epirhandbook.com/en/) which is written in Bookdown (@Xie2020) and is maintained in GitHub (at https://github.com/appliedepi/epiRhandbook_eng). The authors have created an entire textbook using markdown and they use GitHub to handle version issues as well as bug reporting and fixing. This approach has been used widely in the R community for over 20 years now with substantial success. It should come as no surprise to the reader that this paper is also written in markdown and uses GitHub as its source code repository (https://github.com/ainilaha/RNhanes).


## Our Proposed NHANES Paper writing process

Here we sketch out an outline for writing a paper using the tools we mention in order to create a reproducible paper. By reproducible we really mean that once we have agreed on the data to use, that all of the tables, graphs and other data analyses can be reproduced exactly.  Now this is not the concept of scientific reproducibility where one expects to find a similare result when the basic experiment is repeated on a similar but not identical populations, but it is an important goal in and of itself. 

One would first create a new GitHub repository for the project.
Then, identify the variables of interest and the questionnaire files they are in as well as the cycles (years) of data that will be used.  Create an Rmarkdown document and in that use the `nhanesA` package to download the relevant data.  The author will then check that document into the GitHub repository so that all updates and modifications are noted and so that anyone can check out the document.

At this point you will start to write code chunks in the document to first transform and filter the data according to the entry criteria for your study.  For example, you might want to look at blood pressure on adults over 40. On examining the `BXP` tables you find that two different blood pressure measurements (systolic and diastolic) were recorded at two different time points.  You have to decide how to process those data.  Do you take only one, or do you average both? What about people that have only one measurement? Do you keep them or remove them?  All of these decisions will impact the analysis and the actual values you report in your paper.  By including the code to do this processing in your markdown document and reader can check the code for the actual steps you took.

Then as your research progresses you will manipulate the data to compute different summary statistics, perhaps mean diastolic blood pressure by reported ethnicity.  Again the specific details of how you did that will be maintained in the markdown document.  Ultimately you will have finished your analysis and then arrange the outputs, using the tools available for processing Rmarkdown to produce the final paper for publication.
Then you can submit it. And make sure you commit everything you need (images, tables, text etc) to your GitHub repository.

Once the reviews come back you will update and modify that code and text to reflect the changes that have been asked for. And again you will check in all the files and changes. Once your paper is published you can refer interested parties to your GitHub repository where they can download the markdown documents and rerun them. Perhaps they will make changes to your assumptions to see whether the results change. 
 
## Survey Design

An important goal of NHANES is to produce national estimates of a wide variety of health, nutrition and other variables that are representative of the total noninstitutionalized civilian U.S. population. NHANES uses a complex, four-stage sample design and appropriate analyses typically involve using specialized survey analysis procedures that use special weights that account for the sampling scheme that was used to collect the data. NHANES sample weights are provided as part of the data that can be downloaded and there is extensive documentation provided on the CDC website describing the proper use of these weights (https://wwwn.cdc.gov/nchs/nhanes/tutorials/default.aspx). It is important to realize that for a variety of reasons there are different strategies that have been used over time due to improvements in methodology, external factors such as the COVID epidemic, and recently due to a desire to migrate the project to a more longitudinal view. All of these changes have the potential to impact an analysis and often require substantial care on the part of the analyst.

We recommend using the 'survey'(@JSSv009i08) package from CRAN (@Hornik2012TheCR) to perform these analyses and we provide some examples of how to do that in our companion software package `phonto` (@phonto2023).

## Data
 
The `nhanesA` package(@Endres2023) was developed to enable fully customizable retrieval of data NHANES. 
For each cycle of NHANES tables of data within the five publicly available data categories: Demographics, Dietary, Examination, Laboratory and Questionnaire, are produced. There is also limited access data, but that is not publicly available and in order to use a special request must be made.

The available data can be downloaded using https requests from the CDC website. For each table there are two parts, the raw data which is provided in SAS (Statistical Analysis Software) 'XPT' (Transport File Format) format. There is an additional documentation file that describes the data and explains how it is formatted. While many users work off of the raw data that can be problematic due to the way that categorical variables are encoded.  In these files variables like 'sex' or 'ethnicity' are encoded as integer variables and the user needs to translate these into the appropriate character values.  The `nhanesA` package provides a function called `nhanesTranslate` that takes a table name as input and will return the table with all columns translated. We strongly recommend that any analysis be based on translated tables. 

\begin{figure}
  \includegraphics{images/gender.png}
  \includegraphics{images/enthnics.jpg}
  \caption{In the raw data, the gender and ethnicity are encoded as integer instead of character values.}
  \label{fig:DEMO_J}
\end{figure}


Each cycle is based on a different sample of the US population. Within a cycle there are some surveys or assays that are only carried out on a subset of the selected participants while for others everyone is asked.  Respondents do not always answer all questions, and as noted above they are not necessarily included in all of the assays, exams or questionnaires. As a result there can be substantial amounts of missing data and the analyst will need to develop methods for dealing with missingness.

Some questionnaires are reused across cycles. For example the main demography questionnaire is present in all cycles. The CDC uses some naming conventions, but these are not always consistently applied and it is important to be cautious when merging or combining data across questionnaires or cycles.  For example, in the first cycle the demography questionnaire is named `DEMO`, in the second it is named `DEMO_B` and the suffix has been incremented on each cycle up to the present time. However the names of the variables are not guaranteed to be constant, and the actual questions asked may also change over time. Analysts must be careful when working with these tables.

During the 2019-2020 cycle data collection was disrupted by the pandemic. Therefore, the partial 2019-2020 data (herein 2019-March 2020 data) were combined with the full data set from the previous cycle (2017-2018) to create nationally representative 2017-March 2020 pre-pandemic data files.  These data files have the same basic file name, e.g. `DEMO`, but they are named by prepending a `P_` to that, giving `P_DEMO`. These files require special handling and the CDC has provided substantial guidance as well as updating the survey weights etc. Going forward the CDC plans to revamp the entire survey in the 2023-2024 cycle as documented in @Ram2021.

The survey questions are delivered sequentially and there is some amount of structure that will need to be dealt with. In the Blood Pressure and Cholestorol questionnaire for 2005-2006 we show and excerpt of the Data Documentation file in Figure. \ref{fig:BPQ_020}. You can see that in question BPQ_020 that anyone who answered either 'No' or 'Don't know' to the question skipped over question BPQ_030, as it makes little sense for them.  Importantly the value stored in the database for those people for that question was a missing value. Now, in some circumstances an analyst might prefer to assume that if the respondent and not been told that they had high blood pressure once, the also had not been told they had high blood pressure two or more times.   There are many instances in the NHANES data where questions are skipped as part of the survey delivery and it is important that the analyst try to detect those and make reasonable assumptions for the analysis. 


\begin{figure}
  \includegraphics{images/BPQ020D.png}
  \caption{question BPQ\_020.}
  \label{fig:BPQ_020}
\end{figure}


In the NHANES dataset, data coarsening is frequently observed. For instance, the age variable ('RIDAGEYR' in 'DEMO_B') uses a representation where the value 80 denotes individuals aged 80 and above. Similarly, the ratio of family income to poverty ('INDFMPIR') uses the value 5 to indicate a ratio greater than or equal to 5.00. These practices compromise the precision of numerical values in the dataset. Additionally, some variables, although expressed numerically, are better interpreted as categorical data. Take the Body Mass Index ($11.5 \sim 67.3 kg/m^2$, represented as 'BMXBMI' in 'BMX_I') for example. While it is expressed as a continuous number, categorizing it into predefined ranges such as underweight (<18.5), healthy weight (18.5 to <25), overweight (25.0 to <30), and obesity (30.0 or higher) might yield more meaningful analyses.

```{r loadlibs}
# library(nhanesA)
# demo = nhanes("DEMO_J")
```

## Other Approaches

### R Packages

The 'NHANES' package(@Pruim2015) provides a subset of data from the 2009-2010 and 2011-2012 cycles. The authors have created a small subset of the data for teaching purposes. They have included 75 variables and created two datasets. The 'NHANESraw' dataframe is the raw data together with information on the sample weighting scheme. Their 'NHANES' dataframe contains 10,000 rows that were resampled from 'NHANESraw' that *undid* the oversampling and hence analyses using 'NHANES' can be performed without using the survey weights. The authors are quite explicit that this is a teaching resource and that any scientific investigations should rely on the data from the NHANES CDC site and not on their subset.

The 'RNHANES' package (@Susmann2016) is produced by the Silent Spring Institute.
RNHANES provides an easy way to download and analyze data from NHANES with a focus on the laboratory data. They provide methods to find all data files and to download them. They provide a search capability as well as making some attempt to obtain the units of measurement for the laboratory data.  The 'nhanes_load_data' function provides a method for downloading and merging data, although the features are limited. It also has arguments to allow for recording/translating the factor variables, although that seemed to be very slow to run and often resulted in an error.  There are good functions that encapsulate the use of the 'survey' package, but that seems to be at the expense of flexibility in the analysis.

/* xx = nhanes_load_data("UHG", "2011-2012", demographics = TRUE, recode_demographics =TRUE)
 errors for me
*/

### Stata
 https://blog.uvm.edu/tbplante/2018/03/02/downloading-and-analyzing-nhanes-datasets-with-stata-in-a-single-do-file/
  describes how to download and analyze; they have an example of how to merge, translating values seems to be done in a one at a time manual way.
  - they seem unaware of the bpq.020 issues - which we should make sure we mention

### Python
 https://dept.stat.lsa.umich.edu/~kshedden/Python-Workshop/nhanes_data.html
 There is also a package on PyPi - https://pypi.org/project/nhanes/ but it has seen no development since July of 2020
  - none of these seem to address the translation or survey methods requirements of analysing NHANES data.
   You can of course use python to download and then use R connections for the analysis.
   
   
There are two actively maintained Python libraries for working with NHANES data: `nhanes-dl`(https://pypi.org/project/nhanes-dl ) and `pynhanes` (https://pypi.org/project/pynhanes ). In Python, one can utilize Jupyter notebooks to achieve nearly reproducible results. Jupyter notebooks, similar to Rmarkdown, allow for an organized presentation of text, code, and their respective outputs (including plots) within a single document. This facilitates reproducibility, enabling readers to easily replicate and understand the presented work. However, the `nhanes-dl` library is designed to download Continuous NHANES codebooks and convert them into ready-to-use pandas dataframes, although its documentation is somewhat lacking. The `pynhanes` offers several Jupyter notebooks on its GitHub repository(https://github.com/timpyrkov/pynhanes/tree/master/scripts) to demonstrate its usage.



## Discussion and future work

NHANES, with its depth and breadth of health and nutritional data, serves as a cornerstone for myriad research endeavors. However, the intricacies and nuances within the data, combined with the varied methodologies employed across different research efforts, present considerable challenges for reproducibility. The distinct delineation between computational reproducibility and scientific reproducibility is critical. The former ensures that once the dataset is agreed upon, all analytical outputs can be precisely replicated, while the latter emphasizes the need for similar results across analogous, though not identical, populations.

Our proposed process offers a structured approach for researchers using the NHANES dataset. Harnessing the synergy between GitHub, Rmarkdown, and specific packages like `nhanesA`, it sets the stage for a transparent, modular, and rigorously organized research process. Every stage, from data selection to preprocessing decisions and analytical procedures, is systematically recorded and versioned, ensuring transparency and reproducibility.

The complexity of the NHANES survey design further underscores the importance of appropriately considering sample weights and the intricate sampling strategies over time. Methodological shifts due to various factors—innovations in survey techniques, global events like the COVID pandemic, or strategic changes in research focus—highlight the dynamic nature of the dataset.


The use of public data ensures transparency, while open-source software fosters collaboration, enabling researchers across the globe to benefit from shared knowledge. The combination of Markdown and a source code repository like GitHub further fortifies this reproducibility, capturing every stage of analysis and allowing others to trace, validate, and expand upon the original research. Moreover, tools within the `nhanesA` package simplify data retrieval and offer functionality that enhances the integrity of the analysis, such as translating categorical variables. This ensures that research is not only accurate but also more intuitive and user-friendly for subsequent researchers aiming to delve into the dataset.

These tools, though demanding an initial learning curve, are intuitive and efficient. As more researchers embrace these practices, the collective reliability and robustness of NHANES-based research will undoubtedly enhance. By fostering an ecosystem of transparent, replicable, and collaborative research, we can make more informed decisions, richer insights, and a deeper understanding of the NHANES.



## Code availability
The `nahensA` package is available to the public on: https://github.com/cjendres1/nhanes


## Appendix

### Markdown - brief explanation, example and references needed here.