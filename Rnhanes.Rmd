---
title: "Achieving Transparency and Reproducibility in NHANES Research using R"
author: ''
bibliography: references.bib  
# biblio-style: "apalike"
csl: biomed-central.csl
link-citations: true
output:
  pdf_document:
    citation_package: natbib
  bookdown::pdf_book:
    citation_package: biblatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Abstract

NHANES (National Health and Nutrition Examination Survey) covers a very broad array of topics including demography, sociology, health, and nutrition. It has been carried out in two year cycles starting in 1999 and the bulk of the data are public and available to any researcher.  This has made them invaluable in very many areas of research. In this paper we describe methods to aid researchers in developing reproducible research in ways that will allow for sharing and extending previous efforts. We believe that community efforts to enhance reproducibility and sharing of analytic methods will greatly benefit the scientific community and will explain how adopting a few common strategies would be of widespread benefit.

## Introduction

NHANES (National Health and Nutrition Examination Survey) is a pivotal program of studies aimed at evaluating the health and nutritional well-being of both adults and children residing in the United States. Its distinctive feature lies in its comprehensive approach, which combines detailed interviews and thorough physical examinations. NHANES is administered by the National Center for Health Statistics (NCHS), an integral part of the Centers for Disease Control and Prevention (CDC), which holds the responsibility for generating crucial health and vital statistics for the entire nation.
 
 Since 1999, the NHANES survey has been conducted continuously, and the surveys during that period are referred to as "continuous NHANES" to distinguish from several prior surveys. Continuous NHANES surveys are grouped in two-year *cycles*, with the first cycle carried out in 1999-2000.  For the most part the data are public and are very widely used for a variety of different analysis.  In fact, searching PubMed for the published papers that cite NHANES shows that currently more than 5,000 papers per year make some use of the data. The data are available for download from the CDC website, https://www.cdc.gov/nchs/nhanes.htm. Detailed instructions on using the data, how to download it and interpret it are given.
 
However, we have found that replication of published papers remains a challenging endeavor. In our experience even when authors have the best of intentions it is very difficult to replicate the tables and graphs in their papers. This is due to a variety of challenges mainly due to a lack of specifity in reporting the extent and manner of data cleaning, the specification of entry criteria or of case and control definitions, and whether and if any transformation or filtering of data points was carried out.

[We may need a box that describes Markdown documents, Source/Version control systems]

These issues can be ameliorated by using a number of tools that can be adapted to help with reproducibility.  An important development was the concept of *markdown* \cite{Xie2018,Allaire2023}  documents which are documents that integrate software (code) and text. These can be thought of as explicit descriptions of how the figures and the tables in the published paper were created. Markdown documents are processed by different *engines* that transform them into specific outputs such as a PDF format for publication or a HTML output for putting on the web. [Maybe cite the epidemiologists handbook here?]

A second important tool to help with reproducibility is the use of version control systems. These were originally developed for software development but they work equally well for writing papers.  A very widely used tool for version control is GitHub (https://github.com/) and there are many software packages and documents that maintained in 

One popular example of using this approach is the Epidemiologist R (@Ihaka1996) Handbook (https://epirhandbook.com/en/) which is written in Bookdown (@Xie2020) and is maintained in GitHub (at https://github.com/appliedepi/epiRhandbook_eng). The authors have created an entire textbook using markdown and they use GitHub to handle version issues as well as bug reporting and fixing. This approach has been used widely in the R community for over 20 years now with substantial success. It should come as no surprise to the reader that this paper is also written in markdown and uses GitHub as its source code repository (https://github.com/ainilaha/RNhanes).


## Our Proposed Paper writing process

First create a new GitHub repository for the project.

Roughly speaking the procedures used to write a paper based on NHANES data are as follows:

1.Identify the variables of interest and the questionnaire files they are in 

2.The cycles (years) of data that will be used, 

3.Download the data to a local computer for analysis 

We suggest that the code used to download the data and the data themselves (if they are not too large) should be put into the repository so that they can be viewed later and so that anyone wanting to replicate the study would be be able to do so.

## Survey Design

An important goal of NHANES is to produce national estimates of a wide variety of health, nutrition and other variables that are representative of the total noninstitutionalized civilian U.S. population. NHANES uses a complex, four-stage sample design. NHANES sample weights are provided as part of the data that can be downloaded and there is extensive documentation provided on the CDC website describing the proper use of these weights. It is important to realize that for a variety of reasons there are different strategies that have been used over time due to improvements in methodology, external factors such as the COVID epidemic, and recently due to a desire to migrate the project to a more longitudinal view. 

We recommend using the 'survey'(@JSSv009i08) package from CRAN (@Hornik2012TheCR) to perform these analyses and we provide some examples of how to do that in our companion software package 'phonto' (@phonto2023).

## Data
 
The 'nhanesA' package(@Endres2023) was developed to enable fully customizable retrieval of data NHANES. 
For each cycle of NHANES tables of data within the five publicly available data categories: Demographics, Dietary, Examination, Laboratory and Questionnaire, are produced. There is also limited access data, but that is not publicly available and in order to use a special request must be made.

The available data can be downloaded using https requests from the CDC website. For each table there are two parts, the raw data which is provided in SAS (Statistical Analysis Software) 'XPT' (Transport File Format) format. There is an additional documentation file that describes the data and explains how it is formatted. While many users work off of the raw data that can be problematic due to the way that categorical variables are encoded.  In these files variables like 'sex' or 'ethnicity' are encoded as integer variables and the user needs to translate these into the appropriate character values.  The 'nhanesA' package provides a function called 'nhanesTranslate' that takes a table name as input and will return the table with all columns translated. We strongly recommend that any analysis be based on translated tables. 

\begin{figure}
  \includegraphics{images/gender.png}
  \includegraphics{images/enthnics.jpg}
  \caption{In the raw data, the gender and ethnicity are encoder as integer instead of character values.}
  \label{fig:DEMO_J}
\end{figure}


Each cycle is based on a different sample of the US population. Within a cycle there are some surveys or assays that are only carried out on a subset of the selected participants while for others everyone is asked.  Respondents do not always answer all questions, and as noted above they are not necessarily included in all of the assays, exams or questionnaires. As a result there can be substantial amounts of missing data and the analyst will need to develop methods for dealing with missingness.

Some questionnaires are reused across cycles. For example the main demography questionnaire is present in all cycles. The CDC uses some naming conventions, but these are not always consistently applied and it is important to be cautious when merging or combining data across questionnaires or cycles.  For example, in the first cycle the demography questionnaire is named 'DEMO', in the second it is named 'DEMO_B' and the suffix has been incremented on each cycle up to the present time. However the names of the variables are not guaranteed to be constant, and the actual questions asked may also change over time. Analysts must be careful when working with these tables.

During the 2019-2020 cycle data collection was disrupted by the pandemic. Therefore, the partial 2019-2020 data (herein 2019-March 2020 data) were combined with the full data set from the previous cycle (2017-2018) to create nationally representative 2017-March 2020 pre-pandemic data files.  These data files have the same basic file name, e.g. 'DEMO', but they are named by prepending a 'P_' to that, giving 'P_DEMO'. These files require special handling and the CDC has provided substantial guidance as well as updating the survey weights etc. Going forward the CDC plans to revamp the entire survey in the 2023-2024 cycle as documented in @Ram2021.

The survey questions are delivered sequentially and there is some amount of structure that will need to be dealt with. In the Blood Pressure and Cholestorol questionnaire for 2005-2006 we show and excerpt of the Data Documentation file in Figure. \ref{fig:BPQ_020}. You can see that in question BPQ_020 that anyone who answered either 'No' or 'Don't know' to the question skipped over question BPQ_030, as it makes little sense for them.  Importantly the value stored in the database for those people for that question was a missing value. Now, in some circumstances an analyst might prefer to assume that if the respondent and not been told that they had high blood pressure once, the also had not been told they had high blood pressure two or more times.   There are many instances in the NHANES data where questions are skipped as part of the survey delivery and it is important that the analyst try to detect those and make reasonable assumptions for the analysis. 


\begin{figure}
  \includegraphics{images/BPQ020D.png}
  \caption{question BPQ\_020.}
  \label{fig:BPQ_020}
\end{figure}

**The cycles, how they work, some gotchas - maybe the P_ tables; the fact that age seems to have had its max value changed from 70 to 80 - if so when?**


In the NHANES dataset, data coarsening is frequently observed. For instance, the age variable ('RIDAGEYR' in 'DEMO_B') uses a representation where the value 80 denotes individuals aged 80 and above. Similarly, the ratio of family income to poverty ('INDFMPIR') uses the value 5 to indicate a ratio greater than or equal to 5.00. These practices compromise the precision of numerical values in the dataset. Additionally, some variables, although expressed numerically, are better interpreted as categorical data. Take the Body Mass Index ($11.5 \sim 67.3 kg/m^2$, represented as 'BMXBMI' in 'BMX_I') for example. While it is expressed as a continuous number, categorizing it into predefined ranges such as underweight (<18.5), healthy weight (18.5 to <25), overweight (25.0 to <30), and obesity (30.0 or higher) might yield more meaningful analyses.

```{r loadlibs}
# library(nhanesA)
# demo = nhanes("DEMO_J")
```

## Other Approaches

### R Packages

The 'NHANES' package(@Pruim2015) provides a subset of data from the 2009-2010 and 2011-2012 cycles. The authors have created a small subset of the data for teaching purposes. They have included 75 variables and created two datasets. The 'NHANESraw' dataframe is the raw data together with information on the sample weighting scheme. Their 'NHANES' dataframe contains 10,000 rows that were resampled from 'NHANESraw' that *undid* the oversampling and hence analyses using 'NHANES' can be performed without using the survey weights. The authors are quite explicit that this is a teaching resource and that any scientific investigations should rely on the data from the NHANES CDC site and not on their subset.

The 'RNHANES' package (@Susmann2016) is produced by the Silent Spring Institute.
RNHANES provides an easy way to download and analyze data from NHANES with a focus on the laboratory data. They provide methods to find all data files and to download them. They provide a search capability as well as making some attempt to obtain the units of measurement for the laboratory data.  The 'nhanes_load_data' function provides a method for downloading and merging data, although the features are limited. It also has arguments to allow for recording/translating the factor variables, although that seemed to be very slow to run and often resulted in an error.  There are good functions that encapsulate the use of the 'survey' package, but that seems to be at the expense of flexibility in the analysis.

/* xx = nhanes_load_data("UHG", "2011-2012", demographics = TRUE, recode_demographics =TRUE)
 errors for me
*/

### Stata
 https://blog.uvm.edu/tbplante/2018/03/02/downloading-and-analyzing-nhanes-datasets-with-stata-in-a-single-do-file/
  describes how to download and analyze; they have an example of how to merge, translating values seems to be done in a one at a time manual way.
  - they seem unaware of the bpq.020 issues - which we should make sure we mention

### Python
 https://dept.stat.lsa.umich.edu/~kshedden/Python-Workshop/nhanes_data.html
 There is also a package on PyPi - https://pypi.org/project/nhanes/ but it has seen no development since July of 2020
  - none of these seem to address the translation or survey methods requirements of analysing NHANES data.
   You can of course use python to download and then use R connections for the analysis.


## Appendix

### Markdown - brief explanation, example and references needed here.